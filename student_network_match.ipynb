{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# MULTI-MODEL MATCHING\n",
    "# ======================\n",
    "\n",
    "\"\"\"\n",
    "All-in-one script that:\n",
    "1) Loads the dataset, classifies students vs. alumni.\n",
    "2) Builds profiles with clarifying text.\n",
    "3) Generates embeddings from TWO different models (bge-large-en-v1.5 & all-mpnet-base-v2).\n",
    "4) Combines the two similarity scores with weights.\n",
    "5) Applies a smooth penalty + optional boost logic.\n",
    "6) Outputs: all_matches.csv, top10_matches.csv, similarity_matrix.csv.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "#########################\n",
    "# STEP 1: LOAD & PREPARE\n",
    "#########################\n",
    "\n",
    "file_path = r\"C:\\Users\\Guill\\Downloads\\Help Guelph students_alum network with each other (Responses).xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.rename(columns={\n",
    "    \"Are you a student (looking for a job)\": \"is_student\",\n",
    "    \"Are you an alum (looking to help UofG students)\": \"is_alum\",\n",
    "    \"What is/was your major\": \"major\",\n",
    "    \"What is your your field of interest/work  (separate with commas)\": \"field\",\n",
    "    \"What job title do you wanna (or already) have  (separate with commas)\": \"job_title\",\n",
    "    \"Submit your UOFG or WORK email (if possible)\": \"email\"\n",
    "})\n",
    "\n",
    "# Normalize yes/no\n",
    "df[\"is_student\"] = df[\"is_student\"].str.strip().str.lower() == \"yes\"\n",
    "df[\"is_alum\"] = df[\"is_alum\"].str.strip().str.lower() == \"yes\"\n",
    "df[\"email\"] = df[\"email\"].fillna(\"\").astype(str).str.lower()\n",
    "\n",
    "# Classification logic\n",
    "def classify(row):\n",
    "    is_student = row[\"is_student\"]\n",
    "    is_alum = row[\"is_alum\"]\n",
    "    email = row[\"email\"]\n",
    "\n",
    "    if is_student and not is_alum:\n",
    "        return \"student\"\n",
    "    elif not is_student and is_alum:\n",
    "        return \"alum\"\n",
    "    elif is_student and is_alum:\n",
    "        return \"student\" if \"@uoguelph.ca\" in email else \"alum\"\n",
    "    elif not is_student and not is_alum:\n",
    "        return \"student\"\n",
    "    else:\n",
    "        return \"exclude\"\n",
    "\n",
    "# Apply classification\n",
    "df[\"classification\"] = df.apply(classify, axis=1)\n",
    "df = df[df[\"classification\"] != \"exclude\"].copy()\n",
    "\n",
    "# Split\n",
    "students = df[df[\"classification\"] == \"student\"].copy()\n",
    "alumni = df[df[\"classification\"] == \"alum\"].copy()\n",
    "\n",
    "for col in [\"major\", \"field\", \"job_title\"]:\n",
    "    students[col] = students[col].fillna(\"Not specified\")\n",
    "    alumni[col] = alumni[col].fillna(\"Not specified\")\n",
    "\n",
    "# Deduplicate alumni by email\n",
    "alumni = alumni.sort_values(by=[\"job_title\", \"field\"], ascending=False)\n",
    "alumni = alumni.drop_duplicates(subset=[\"email\"], keep=\"first\")\n",
    "\n",
    "#########################\n",
    "# STEP 2: BUILD PROFILES\n",
    "#########################\n",
    "\n",
    "def build_profile(row, role=\"student\"):\n",
    "    if role == \"student\":\n",
    "        return (\n",
    "            f\"This is a student. Their major is {row['major']}. \"\n",
    "            f\"They want to work as: {row['job_title']}. \"\n",
    "            f\"Their interests are: {row['field']}.\"\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            f\"This is an alum. Their major was {row['major']}. \"\n",
    "            f\"They work as: {row['job_title']}. \"\n",
    "            f\"Their field of work includes: {row['field']}.\"\n",
    "        )\n",
    "\n",
    "students[\"profile\"] = students.apply(lambda r: build_profile(r, \"student\"), axis=1)\n",
    "alumni[\"profile\"] = alumni.apply(lambda r: build_profile(r, \"alum\"), axis=1)\n",
    "\n",
    "############################\n",
    "# STEP 3: MULTI-MODEL SETUP\n",
    "############################\n",
    "\n",
    "model_bge = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")\n",
    "model_mpnet = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "# Encode profiles\n",
    "student_profiles = students[\"profile\"].tolist()\n",
    "alum_profiles = alumni[\"profile\"].tolist()\n",
    "\n",
    "student_emb_bge = model_bge.encode(student_profiles, convert_to_tensor=True)\n",
    "alum_emb_bge = model_bge.encode(alum_profiles, convert_to_tensor=True)\n",
    "\n",
    "student_emb_mpnet = model_mpnet.encode(student_profiles, convert_to_tensor=True)\n",
    "alum_emb_mpnet = model_mpnet.encode(alum_profiles, convert_to_tensor=True)\n",
    "\n",
    "#########################\n",
    "# STEP 4: PENALTY SYSTEM\n",
    "#########################\n",
    "\n",
    "def get_keywords(text):\n",
    "    return set(re.findall(r\"[a-zA-Z]+\", text.lower()))\n",
    "\n",
    "def apply_penalty_and_boost(student_row, alum_row, base_score):\n",
    "    student_keys = get_keywords(student_row[\"major\"]) | get_keywords(student_row[\"field\"]) | get_keywords(student_row[\"job_title\"])\n",
    "    alum_keys = get_keywords(alum_row[\"major\"]) | get_keywords(alum_row[\"field\"]) | get_keywords(alum_row[\"job_title\"])\n",
    "    overlap = student_keys.intersection(alum_keys)\n",
    "\n",
    "    # Graduated penalty\n",
    "    if len(overlap) < 2:\n",
    "        penalty = 10\n",
    "    elif len(overlap) < 5:\n",
    "        penalty = 5\n",
    "    else:\n",
    "        penalty = 0\n",
    "\n",
    "    # Apply penalty\n",
    "    score = base_score - penalty\n",
    "\n",
    "    # Boost for important shared keywords\n",
    "    boost_keywords = student_keys & alum_keys & {\"data\", \"finance\", \"marketing\", \"health\", \"research\"}\n",
    "    if len(boost_keywords) > 0:\n",
    "        score += 5\n",
    "\n",
    "    return max(0, min(100, round(score)))\n",
    "\n",
    "#########################\n",
    "# STEP 5: COMPUTE MATCHES\n",
    "#########################\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, student_row in students.iterrows():\n",
    "    for j, alum_row in alumni.iterrows():\n",
    "        s_idx = students.index.get_loc(i)\n",
    "        a_idx = alumni.index.get_loc(j)\n",
    "\n",
    "        # Compute similarity scores\n",
    "        score_bge = util.cos_sim(student_emb_bge[s_idx], alum_emb_bge[a_idx]).item()\n",
    "        score_mpnet = util.cos_sim(student_emb_mpnet[s_idx], alum_emb_mpnet[a_idx]).item()\n",
    "\n",
    "        # Weighted combination\n",
    "        combined_sim = 0.65 * score_bge + 0.35 * score_mpnet\n",
    "        base_score = ((combined_sim + 1) / 2) * 100\n",
    "\n",
    "        # Final score with penalty and boost\n",
    "        final_score = apply_penalty_and_boost(student_row, alum_row, base_score)\n",
    "\n",
    "        results.append({\n",
    "            \"student_email\": student_row[\"email\"],\n",
    "            \"alum_email\": alum_row[\"email\"],\n",
    "            \"match_score\": final_score,\n",
    "            \"student_profile\": student_row[\"profile\"],\n",
    "            \"alum_profile\": alum_row[\"profile\"]\n",
    "        })\n",
    "\n",
    "match_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort and drop duplicates\n",
    "match_df = match_df.sort_values(by=\"match_score\", ascending=False)\n",
    "match_df = match_df.drop_duplicates(subset=[\"student_email\", \"alum_email\"], keep=\"first\")\n",
    "\n",
    "#########################\n",
    "# STEP 6: SAVE OUTPUTS\n",
    "#########################\n",
    "\n",
    "downloads_path = r\"C:\\Users\\Guill\\Downloads\"\n",
    "\n",
    "# all matches\n",
    "match_df.to_csv(f\"{downloads_path}\\\\all_matches.csv\", index=False)\n",
    "\n",
    "# top 10 per student\n",
    "top10_df = match_df.sort_values(by=[\"student_email\", \"match_score\"], ascending=[True, False])\n",
    "top10_df = top10_df.groupby(\"student_email\").head(10)\n",
    "top10_df.to_csv(f\"{downloads_path}\\\\top10_matches.csv\", index=False)\n",
    "\n",
    "# matrix, using pivot_table in case duplicates\n",
    "matrix_df = match_df.pivot_table(\n",
    "    index=\"student_email\",\n",
    "    columns=\"alum_email\",\n",
    "    values=\"match_score\",\n",
    "    aggfunc=\"max\"\n",
    ")\n",
    "matrix_df.to_csv(f\"{downloads_path}\\\\similarity_matrix.csv\")\n",
    "\n",
    "print(\"‚úÖ Multi-model matching complete! Check your Downloads folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count unique alumni in full and top10 match files\n",
    "all_alums = set(match_df[\"alum_email\"].unique())\n",
    "top10_alums = set(top10_df[\"alum_email\"].unique())\n",
    "\n",
    "# Find missing alumni\n",
    "missing_alums = all_alums - top10_alums\n",
    "\n",
    "# Output result\n",
    "if len(missing_alums) == 0:\n",
    "    print(\"‚úÖ Every alum appears in at least one student's Top 10.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {len(missing_alums)} alumni do NOT appear in any top 10 list.\")\n",
    "    print(\"Emails of missing alumni:\")\n",
    "    print(missing_alums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many times each alum appears in students' Top 10 matches\n",
    "alum_popularity = top10_df[\"alum_email\"].value_counts().reset_index()\n",
    "alum_popularity.columns = [\"alum_email\", \"times_appeared\"]\n",
    "\n",
    "# Merge with alum details for context (job title, field, etc.)\n",
    "alum_details = alumni[[\"email\", \"major\", \"job_title\", \"field\"]].rename(columns={\"email\": \"alum_email\"})\n",
    "alum_ranked = pd.merge(alum_popularity, alum_details, on=\"alum_email\", how=\"left\")\n",
    "\n",
    "# Sort by most popular\n",
    "alum_ranked = alum_ranked.sort_values(by=\"times_appeared\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alum_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "# Filter for a specific alum\n",
    "alum_email = \"cdervaric@sylvite.ca\"\n",
    "alum_matches = match_df[match_df[\"alum_email\"] == alum_email]\n",
    "\n",
    "# Top 10-15 matches\n",
    "top_matches = alum_matches.sort_values(by=\"match_score\", ascending=False).head(30)\n",
    "top_matches[[\"student_email\", \"match_score\", \"student_profile\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "match_df[\"match_score\"].hist(bins=30)\n",
    "plt.title(\"Match Score Distribution\")\n",
    "plt.xlabel(\"Match Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(match_df[\"match_score\"], bins=30, kde=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_check = match_df.groupby(\"student_email\")[\"match_score\"].agg([\"min\", \"max\", \"mean\", \"std\"])\n",
    "spread_check[\"range\"] = spread_check[\"max\"] - spread_check[\"min\"]\n",
    "spread_check = spread_check.sort_values(by=\"range\", ascending=True)\n",
    "print(\"üìâ Students with lowest score range:\")\n",
    "spread_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_check = top10_df.groupby(\"student_email\")[\"match_score\"].std().reset_index()\n",
    "flat_check.columns = [\"student_email\", \"top10_std\"]\n",
    "print(\"Students with flat top 10s (low std dev):\")\n",
    "print(flat_check.nsmallest(10, \"top10_std\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_alums = match_df[\"alum_email\"].value_counts().head(10).index.tolist()\n",
    "alum_subset = match_df[match_df[\"alum_email\"].isin(popular_alums)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=\"alum_email\", y=\"match_score\", data=alum_subset)\n",
    "plt.title(\"üì¶ Score Spread for Top 5 Most Frequent Alumni\")\n",
    "plt.xlabel(\"Alum Email\")\n",
    "plt.ylabel(\"Match Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Average Score & Match Count ===\n",
    "alum_score_stats = match_df.groupby(\"alum_email\")[\"match_score\"].agg([\"mean\", \"count\", \"max\"]).reset_index()\n",
    "alum_score_stats.columns = [\"alum_email\", \"avg_score\", \"times_matched\", \"peak_score\"]\n",
    "\n",
    "# === Step 2: Top 10 Appearance Count ===\n",
    "top10_counts = top10_df[\"alum_email\"].value_counts().reset_index()\n",
    "top10_counts.columns = [\"alum_email\", \"top10_count\"]\n",
    "\n",
    "# === Step 3: Merge All Stats ===\n",
    "alum_analysis = pd.merge(alum_score_stats, top10_counts, on=\"alum_email\", how=\"left\").fillna(0)\n",
    "alum_analysis[\"top10_count\"] = alum_analysis[\"top10_count\"].astype(int)\n",
    "\n",
    "# === Step 4: Add Alumni Info ===\n",
    "alum_info = alumni[[\"email\", \"major\", \"job_title\", \"field\"]].rename(columns={\"email\": \"alum_email\"})\n",
    "alum_analysis = pd.merge(alum_analysis, alum_info, on=\"alum_email\", how=\"left\")\n",
    "\n",
    "# === Step 5: Sort by Top 10 Count then Avg Score ===\n",
    "alum_analysis = alum_analysis.sort_values(by=[\"top10_count\", \"avg_score\"], ascending=[False, True])\n",
    "\n",
    "# === Step 6: Save and Show ===\n",
    "alum_analysis.to_csv(f\"{downloads_path}\\\\alum_popularity_quality_full.csv\", index=False)\n",
    "\n",
    "print(\"üìä Alumni with high top 10 counts but low average scores (possible filler matches):\")\n",
    "print(alum_analysis[alum_analysis[\"top10_count\"] >= 5].head(10))\n",
    "\n",
    "print(\"\\nüåü Alumni with best single matches (peak score):\")\n",
    "print(alum_analysis.sort_values(by='peak_score', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=alum_analysis, x=\"top10_count\", y=\"avg_score\")\n",
    "plt.title(\"üéØ Alumni: Frequency in Top 10 vs. Average Match Score\")\n",
    "plt.xlabel(\"Times in Top 10 Lists\")\n",
    "plt.ylabel(\"Average Match Score\")\n",
    "plt.axhline(70, color=\"red\", linestyle=\"--\", label=\"Score Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the peak (max) match score per alum\n",
    "alum_peak_scores = match_df.groupby(\"alum_email\")[\"match_score\"].max().reset_index()\n",
    "alum_peak_scores.columns = [\"alum_email\", \"peak_match_score\"]\n",
    "\n",
    "# Optional: Merge with alum info\n",
    "alum_info = alumni[[\"email\", \"major\", \"job_title\", \"field\"]].rename(columns={\"email\": \"alum_email\"})\n",
    "alum_peak_scores = pd.merge(alum_peak_scores, alum_info, on=\"alum_email\", how=\"left\")\n",
    "\n",
    "# Sort by peak match score\n",
    "alum_peak_scores = alum_peak_scores.sort_values(by=\"peak_match_score\", ascending=False)\n",
    "\n",
    "# Show top 10\n",
    "print(\"üåü Alumni with highest single match scores:\")\n",
    "print(alum_peak_scores.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Top 3 Matches per Student ===\n",
    "top3_df = match_df.sort_values(by=[\"student_email\", \"match_score\"], ascending=[True, False])\n",
    "top3_df = top3_df.groupby(\"student_email\").head(3)\n",
    "\n",
    "# Save it\n",
    "\n",
    "# === Step 2: Most Popular Alumni in Top 3 ===\n",
    "top3_popularity = top3_df[\"alum_email\"].value_counts().reset_index()\n",
    "top3_popularity.columns = [\"alum_email\", \"top3_count\"]\n",
    "\n",
    "# Merge with alum info\n",
    "top3_popular_alums = pd.merge(top3_popularity, alumni.rename(columns={\"email\": \"alum_email\"}), on=\"alum_email\", how=\"left\")\n",
    "\n",
    "# Save and show\n",
    "\n",
    "print(\"üèÖ Most popular alumni in Top 3 lists:\")\n",
    "print(top3_popular_alums.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique alumni in full and top10 match files\n",
    "all_alums = set(match_df[\"alum_email\"].unique())\n",
    "top3_popular_alums = set(top3_popular_alums[\"alum_email\"].unique())\n",
    "\n",
    "# Find missing alumni\n",
    "missing_alums = all_alums - top3_popular_alums\n",
    "\n",
    "# Output result\n",
    "if len(missing_alums) == 0:\n",
    "    print(\"‚úÖ Every alum appears in at least one student's Top 10.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è {len(missing_alums)} alumni do NOT appear in any top 10 list.\")\n",
    "    print(\"Emails of missing alumni:\")\n",
    "    print(missing_alums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_top_x(match_df, alumni_emails, max_x=20):\n",
    "    for x in range(1, max_x + 1):\n",
    "        top_x_df = match_df.sort_values(by=[\"student_email\", \"match_score\"], ascending=[True, False])\n",
    "        top_x_df = top_x_df.groupby(\"student_email\").head(x)\n",
    "        \n",
    "        matched_alums = set(top_x_df[\"alum_email\"].unique())\n",
    "        missing = set(alumni_emails) - matched_alums\n",
    "        \n",
    "        if len(missing) == 0:\n",
    "            print(f\"‚úÖ Minimum top X where all alumni are included: Top {x}\")\n",
    "            return x, top_x_df  # also return the DataFrame so you can save it\n",
    "    print(f\"‚ùå No X ‚â§ {max_x} includes all alumni.\")\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_alumni_emails = alumni[\"email\"].unique()\n",
    "\n",
    "# Run search\n",
    "top_x_value, top_x_df = find_min_top_x(match_df, all_alumni_emails, max_x=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Top 5 Matches per Student ===\n",
    "top5_df = match_df.sort_values(by=[\"student_email\", \"match_score\"], ascending=[True, False])\n",
    "top5_df = top5_df.groupby(\"student_email\").head(5)\n",
    "\n",
    "# Save it\n",
    "\n",
    "# === Step 2: Most Popular Alumni in Top 5 ===\n",
    "top5_popularity = top5_df[\"alum_email\"].value_counts().reset_index()\n",
    "top5_popularity.columns = [\"alum_email\", \"top5_count\"]\n",
    "\n",
    "# Merge with alum info\n",
    "top5_popular_alums = pd.merge(top5_popularity, alumni.rename(columns={\"email\": \"alum_email\"}), on=\"alum_email\", how=\"left\")\n",
    "\n",
    "# Save and show\n",
    "\n",
    "print(\"üèÖ Most popular alumni in Top 5 lists:\")\n",
    "print(top5_popular_alums.tail(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# ‚úÖ Use top 5 matches (not balanced)\n",
    "grouped_matches = top5_df.groupby(\"student_email\")\n",
    "\n",
    "email_bodies = []\n",
    "\n",
    "for student_email, group in grouped_matches:\n",
    "    matches = group.sort_values(by=\"match_score\", ascending=False)\n",
    "\n",
    "    # Compose match details\n",
    "    match_lines = []\n",
    "    for _, row in matches.iterrows():\n",
    "        match_lines.append(\n",
    "            f\"- {row['alum_profile'].strip()} \\n  ‚Üí Match Score: {row['match_score']}%\\n  ‚Üí Email: {row['alum_email']}\"\n",
    "        )\n",
    "\n",
    "    matches_text = \"\\n\\n\".join(match_lines)\n",
    "    subject = \"Your Top 5 Alumni Matches ‚Äì UofG Memes Networking Initiative\"\n",
    "\n",
    "    # Email body with cleaned formatting\n",
    "    body = f\"\"\"To: {student_email}\n",
    "Subject: {subject}\n",
    "\n",
    "Hi,\n",
    "\n",
    "I've finished the alumni matching system based on your responses and a semantic AI-based algorithm. You've been matched with 5 alumni based on your major, career interests, and goals. Match scores range from 0 to 100 ‚Äî with 100 being the best possible match.\n",
    "\n",
    "Here are your top 5 matches:\n",
    "\n",
    "{matches_text}\n",
    "\n",
    "üéØ What to do next:\n",
    "You should reach out to the people above.\n",
    "\n",
    "If you're unsure how to reach out, here‚Äôs a message you can use:\n",
    "\n",
    "---\n",
    "Hi [Name],\n",
    "\n",
    "We were matched through the UofG Memes initiative. I saw that you work in [insert company or field], and I‚Äôm currently studying [your major] and interested in [your career goal or field].\n",
    "\n",
    "I was wondering if you‚Äôd be open to a quick 15-minute call to share a bit about what you do, your journey, and how you got into your current role. I‚Äôd really appreciate your insights.\n",
    "\n",
    "Thanks so much!\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è If none of these people reply within a week or if the matches don‚Äôt seem relevant, just let me know and I can send your full top 10 matches so you can explore more options.\n",
    "\n",
    "üìå Just a quick heads-up about expectations:\n",
    "\n",
    "Most of the people who filled out this form and were matched with you probably graduated in the last 5 years. That means it's unlikely they can get you a job right away ‚Äî and that‚Äôs totally normal.\n",
    "\n",
    "The point of this is networking. It‚Äôs about starting conversations, learning how people broke into your field, and having people know who you are. If they get to know you, they might think of you when an opportunity comes up, or they might connect you with someone more senior at their company.\n",
    "\n",
    "But don‚Äôt go in expecting job offers. Think of this as planting seeds for the future ‚Äî the kind that lead to opportunities down the line.\n",
    "\n",
    "Let me know if you need anything else or want to try out more matches later on.\n",
    "\n",
    "‚Äî\n",
    "Memes\n",
    "\"\"\"\n",
    "\n",
    "    email_bodies.append({\"student_email\": student_email, \"email_body\": body})\n",
    "\n",
    "# Save each email as a separate .txt file\n",
    "output_folder = os.path.join(downloads_path, \"student_emails_txt\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for email in email_bodies:\n",
    "    filename = os.path.join(output_folder, f\"{email['student_email'].replace('@', '_at_')}.txt\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(email[\"email_body\"])\n",
    "\n",
    "print(f\"‚úÖ Saved all student emails with 'To' and 'Subject' to: {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Group matched students by each alum\n",
    "alum_groups = top5_df.groupby(\"alum_email\")\n",
    "alum_emails = []\n",
    "\n",
    "# Output folder for .txt files\n",
    "alum_email_folder = os.path.join(downloads_path, \"alumni_emails_txt\")\n",
    "os.makedirs(alum_email_folder, exist_ok=True)\n",
    "\n",
    "for alum_email, group in alum_groups:\n",
    "    student_matches = group.sort_values(by=\"match_score\", ascending=False)\n",
    "    total_matches = len(student_matches)\n",
    "\n",
    "    # Format matched students\n",
    " student_matches.iterrows():\n",
    "        student_lines.append(\n",
    "            f    student_lines = []\n",
    "    for _, row in\"- {row['student_profile']} \\n  ‚Üí Match Score: {row['match_score']}%\\n  ‚Üí Email: {row['student_email']}\"\n",
    "        )\n",
    "\n",
    "    student_text = \"\\n\\n\".join(student_lines)\n",
    "\n",
    "    # Subject line\n",
    "    subject = \"Thank you for joining the UofG Memes Networking Initiative\"\n",
    "\n",
    "    # Full email body\n",
    "    body = f\"\"\"To: {alum_email}\n",
    "Subject: {subject}\n",
    "\n",
    "Hi,\n",
    "\n",
    "Thank you so much for volunteering to support UofG students!\n",
    "\n",
    "You‚Äôve been matched with **{total_matches} student{'s' if total_matches > 1 else ''}** based on the interests, fields, and job titles you listed in your response. I built a matching system that uses semantic AI models to compare your answers to students' responses. It looks at the meaning behind what you wrote ‚Äî your major, your job, and your industry ‚Äî and finds students with similar goals or experiences.\n",
    "\n",
    "üéØ **What this means** is that the following student(s) had profiles that were most similar to yours in terms of interests, career paths, or fields.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "üìã **Note on Profile Expansion**\n",
    "\n",
    "Some responses were a bit short or vague. In those cases, I used what was already written to expand the descriptions a little, just to make sure the matches made sense and that no one got overlooked due to missing info.\n",
    "\n",
    "---\n",
    "\n",
    "üí¨ **What happens next?**\n",
    "\n",
    "It‚Äôs the student‚Äôs responsibility to reach out to you. When they do, all I ask is that you try to make time for a short chat ‚Äî even just 15 minutes ‚Äî to help them better understand what you do, how you got there, or what advice you might have.\n",
    "\n",
    "ü§ù **If possible**, please try to respond within a week ‚Äî even if it‚Äôs just a quick message letting them know your availability.\n",
    "\n",
    "üòÖ **Feeling overwhelmed?** That‚Äôs totally okay. If you‚Äôre too busy right now, you can always reply with a note asking them to follow up later ‚Äî in a week, two weeks, or even a month. They‚Äôll appreciate your honesty and it helps set clear expectations.\n",
    "\n",
    "---\n",
    "\n",
    "This project only works because of people like you who are willing to take a little time to support others. Even a quick chat can make a huge difference to someone just starting out.\n",
    "\n",
    "Thank you again ‚Äî I really appreciate it.\n",
    "\n",
    "‚Äî\n",
    "Memes\n",
    "\"\"\"\n",
    "\n",
    "    alum_emails.append({\n",
    "        \"alum_email\": alum_email,\n",
    "        \"email_body\": body\n",
    "    })\n",
    "\n",
    "    # Save each email as .txt file\n",
    "    filename = os.path.join(alum_email_folder, f\"{alum_email.replace('@', '_at_')}.txt\")\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(body)\n",
    "\n",
    "# Optional: Save all as .csv backup\n",
    "alum_email_df = pd.DataFrame(alum_emails)\n",
    "\n",
    "print(f\"‚úÖ Saved individual emails to: {alum_email_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique alumni emails from top 5 matches\n",
    "all_alum_emails = sorted(top5_df[\"alum_email\"].unique().tolist())\n",
    "\n",
    "# Print each one on a new line\n",
    "for email in all_alum_emails:\n",
    "    print(email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import base64\n",
    "# from email.mime.text import MIMEText\n",
    "# from google.oauth2.credentials import Credentials\n",
    "# from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "# from googleapiclient.discovery import build\n",
    "\n",
    "# # ================\n",
    "# # SETUP GMAIL API\n",
    "# # ================\n",
    "# SCOPES = [\"https://www.googleapis.com/auth/gmail.send\"]\n",
    "# CLIENT_SECRET_FILE = \n",
    "# TOKEN_FILE = \"token.json\"  # Saved token after first login\n",
    "\n",
    "# creds = None\n",
    "# if os.path.exists(TOKEN_FILE):\n",
    "#     creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "# else:\n",
    "#     flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\n",
    "#     creds = flow.run_local_server(port=0)\n",
    "#     with open(TOKEN_FILE, \"w\") as token:\n",
    "#         token.write(creds.to_json())\n",
    "\n",
    "# service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "# # ==========================\n",
    "# # READ & SEND TXT EMAIL FILES\n",
    "# # ==========================\n",
    "# email_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"student_emails_txt\")\n",
    "\n",
    "# for filename in os.listdir(email_folder):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         file_path = os.path.join(email_folder, filename)\n",
    "#         with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             lines = f.read().splitlines()\n",
    "\n",
    "#         # Parse To and Subject\n",
    "#         to_line = lines[0].strip()\n",
    "#         subject_line = lines[1].strip()\n",
    "#         body = \"\\n\".join(lines[3:])  # skip 'To:' and 'Subject:' and one blank line\n",
    "\n",
    "#         to_email = to_line.replace(\"To:\", \"\").strip()\n",
    "#         subject = subject_line.replace(\"Subject:\", \"\").strip()\n",
    "\n",
    "#         # Build MIME message\n",
    "#         message = MIMEText(body)\n",
    "#         message[\"to\"] = to_email\n",
    "#         message[\"subject\"] = subject\n",
    "#         raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "\n",
    "#         try:\n",
    "#             send_result = service.users().messages().send(\n",
    "#                 userId=\"me\", body={\"raw\": raw_message}\n",
    "#             ).execute()\n",
    "#             print(f\"‚úÖ Sent to: {to_email}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"‚ùå Failed to send to: {to_email} ‚Üí {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from email.mime.text import MIMEText\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# ================\n",
    "# SETUP GMAIL API\n",
    "# ================\n",
    "SCOPES = [\"https://www.googleapis.com/auth/gmail.send\"]\n",
    "CLIENT_SECRET_FILE = r\"C:\\Users\\Guill\\Downloads\\client_secret_803122994384-i9niq835sd64kmvm4uft57fe04qq49ff.apps.googleusercontent.com.json\"\n",
    "TOKEN_FILE = \"token.json\"\n",
    "\n",
    "creds = None\n",
    "if os.path.exists(TOKEN_FILE):\n",
    "    creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "else:\n",
    "    flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)\n",
    "    creds = flow.run_local_server(port=0)\n",
    "    with open(TOKEN_FILE, \"w\") as token:\n",
    "        token.write(creds.to_json())\n",
    "\n",
    "service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "# ==========================\n",
    "# SEND FOLLOW-UP TO STUDENTS\n",
    "# ==========================\n",
    "email_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\", \"student_emails_txt\")\n",
    "\n",
    "for filename in os.listdir(email_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(email_folder, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.read().splitlines()\n",
    "            if not lines:\n",
    "                continue\n",
    "\n",
    "        # First line contains email like: \"To: student@email.com\"\n",
    "        to_line = lines[0].strip()\n",
    "        if not to_line.lower().startswith(\"to:\"):\n",
    "            continue\n",
    "        to_email = to_line.replace(\"To:\", \"\").strip()\n",
    "\n",
    "        subject = \"Email confirmation?\"\n",
    "        body = \"\"\"Hey ‚Äî Some people have told me they didnt get the last email with their matches. Im just checking if you got the alumni matches I sent earlier.\n",
    "\n",
    "Can you reply ‚Äúyes‚Äù if you got it, or ‚Äúno‚Äù if you didn‚Äôt?\n",
    "\n",
    "Thanks!\"\"\"\n",
    "\n",
    "        # Build MIME message\n",
    "        message = MIMEText(body)\n",
    "        message[\"to\"] = to_email\n",
    "        message[\"subject\"] = subject\n",
    "        raw_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "\n",
    "        try:\n",
    "            send_result = service.users().messages().send(\n",
    "                userId=\"me\", body={\"raw\": raw_message}\n",
    "            ).execute()\n",
    "            print(f\"‚úÖ Sent follow-up to: {to_email}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to send to: {to_email} ‚Üí {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Subset for visualization: top N matches only\n",
    "top_matches = match_df.sort_values(by=\"match_score\", ascending=False).head(300)\n",
    "\n",
    "# Create graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and weighted edges\n",
    "for _, row in top_matches.iterrows():\n",
    "    student = f\"S: {row['student_email']}\"\n",
    "    alum = f\"A: {row['alum_email']}\"\n",
    "    score = row['match_score']\n",
    "\n",
    "    G.add_node(student, type='student')\n",
    "    G.add_node(alum, type='alum')\n",
    "    G.add_edge(student, alum, weight=score)\n",
    "\n",
    "# Draw graph\n",
    "plt.figure(figsize=(14, 12))\n",
    "pos = nx.spring_layout(G, k=0.25)  # Force-directed layout\n",
    "\n",
    "node_colors = ['skyblue' if n.startswith(\"S:\") else 'salmon' for n in G.nodes()]\n",
    "edges = G.edges(data=True)\n",
    "weights = [d['weight'] / 10 for (_, _, d) in edges]  # Scale down for visual\n",
    "\n",
    "nx.draw(G, pos, node_color=node_colors, edge_color='gray', width=weights,\n",
    "        with_labels=False, alpha=0.8, node_size=100)\n",
    "plt.title(\"Student-Alumni Match Network\", fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# -------------------------\n",
    "# STEP 1: Top Matches Subset\n",
    "# -------------------------\n",
    "top_matches = match_df.sort_values(by=\"match_score\", ascending=False).head(300)\n",
    "\n",
    "# -------------------------\n",
    "# STEP 2: Embed & Cluster Alumni\n",
    "# -------------------------\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "alum_profiles = alumni.set_index(\"email\").loc[top_matches[\"alum_email\"].unique()][\"profile\"].tolist()\n",
    "alum_embeddings = model.encode(alum_profiles)\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=42)\n",
    "cluster_ids = kmeans.fit_predict(alum_embeddings)\n",
    "\n",
    "alum_cluster_map = {\n",
    "    email: cluster for email, cluster in zip(top_matches[\"alum_email\"].unique(), cluster_ids)\n",
    "}\n",
    "\n",
    "cluster_labels = {\n",
    "    0: \"Finance / Data\",\n",
    "    1: \"Marketing / Business\",\n",
    "    2: \"Science / Health\",\n",
    "    3: \"Engineering / Tech\",\n",
    "    4: \"Education / Social\",\n",
    "    5: \"Environment / Law\"\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# STEP 3: Build Graph\n",
    "# -------------------------\n",
    "G = nx.Graph()\n",
    "\n",
    "for _, row in top_matches.iterrows():\n",
    "    student = f\"S: {row['student_email']}\"\n",
    "    alum = f\"A: {row['alum_email']}\"\n",
    "    score = row['match_score']\n",
    "\n",
    "    G.add_node(student, type='student', cluster=None)\n",
    "    G.add_node(alum, type='alum', cluster=alum_cluster_map[row['alum_email']])\n",
    "    G.add_edge(student, alum, weight=score)\n",
    "\n",
    "# -------------------------\n",
    "# STEP 4: Draw Graph\n",
    "# -------------------------\n",
    "plt.figure(figsize=(14, 12))\n",
    "pos = nx.spring_layout(G, k=0.25, seed=42)\n",
    "\n",
    "# Colors: brighter students, deeper alumni cluster colors\n",
    "node_colors = []\n",
    "for n, attr in G.nodes(data=True):\n",
    "    if attr['type'] == 'student':\n",
    "        node_colors.append(\"#000000\")  # Bright gold\n",
    "    else:\n",
    "        cluster_id = attr['cluster']\n",
    "        cluster_color = plt.cm.Dark2(cluster_id % 8)  # Deeper tone\n",
    "        node_colors.append(cluster_color)\n",
    "\n",
    "# Edge weights ‚Äì thinner\n",
    "weights = [d['weight'] / 35 for (_, _, d) in G.edges(data=True)]\n",
    "\n",
    "# Draw\n",
    "nx.draw(\n",
    "    G, pos, node_color=node_colors, edge_color='gray', width=weights,\n",
    "    with_labels=False, node_size=120, alpha=0.9\n",
    ")\n",
    "\n",
    "# Legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"#000000\", edgecolor='k', label='Student')\n",
    "] + [\n",
    "    Patch(facecolor=plt.cm.Dark2(i % 8), edgecolor='k', label=label)\n",
    "    for i, label in cluster_labels.items()\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, title=\"Node Type / Cluster\", loc=\"upper left\")\n",
    "plt.title(\"Student-Alumni Match Network with Thematic Clusters\", fontsize=16)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
